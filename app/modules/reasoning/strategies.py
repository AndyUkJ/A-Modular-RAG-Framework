from __future__ import annotations
from typing import Any, Dict, List, Tuple, Iterable, Set
import re
from collections import Counter
import math
import logging

logger = logging.getLogger(__name__)

# -------- text utils --------

def _tokenize(text: str) -> List[str]:
    return [t for t in re.split(r"[^a-zA-Z0-9]+", (text or "").lower()) if t]

def overlap_score(a: str, b: str) -> float:
    """è¯é¡¹äº¤é›†åˆ†æ•°ï¼š|Aâˆ©B| / (1 + log(|B|))ï¼Œé¼“åŠ±çŸ­è¯æ®æ®µè½"""
    A, B = set(_tokenize(a)), set(_tokenize(b))
    if not B:
        return 0.0
    inter = len(A & B)
    return inter / (1.0 + math.log(1.0 + len(B)))

# å…¼å®¹æ—§ä»£ç ï¼šéƒ¨åˆ†å†å²ç‰ˆæœ¬ç”¨çš„æ˜¯ `_overlap_score`
def _overlap_score(a: str, b: str) -> float:
    return overlap_score(a, b)

def normalize_answer(s: str) -> str:
    """è‡ªæ´½æŠ•ç¥¨ç”¨ï¼šå°å†™ã€å»æ ‡ç‚¹ç©ºç™½ã€æ¶ˆæ‹¬å·å¼•ç”¨"""
    s = s or ""
    s = re.sub(r"\[[^\]]+\]", " ", s)         # å»æ‰å†…è”å¼•ç”¨ï¼Œå¦‚ [#3]
    s = re.sub(r"[^a-zA-Z0-9]+", " ", s)      # éå­—æ¯æ•°å­—å˜ç©ºæ ¼
    s = s.strip().lower()
    s = re.sub(r"\s+", " ", s)
    return s

# -------- LLM output coerce --------

def coerce_text(out: Any) -> str:
    """
    å°†ä¸åŒ provider çš„è¿”å›ç»“æ„å°½é‡æ”¶æ•›ä¸º strã€‚
    ä¿ç•™æ—§é€»è¾‘ï¼Œæ–°å¢æ›´å¤šå…œåº•åˆ†æ”¯ã€‚
    """
    if out is None:
        return ""
    if isinstance(out, str):
        return out

    if isinstance(out, dict):
        # 1) ç›´æ¥ text
        t = out.get("text")
        if isinstance(t, str):
            return t
        if isinstance(t, dict):
            if isinstance(t.get("text"), str):
                return t["text"]
            c = t.get("content")
            if isinstance(c, str):
                return c
            if isinstance(c, list):
                for item in c:
                    if isinstance(item, dict) and isinstance(item.get("text"), str):
                        return item["text"]

        # 2) message.content
        msg = out.get("message")
        if isinstance(msg, dict):
            c = msg.get("content")
            if isinstance(c, str):
                return c
            if isinstance(c, list):
                for item in c:
                    if isinstance(item, dict) and item.get("type") == "text" and isinstance(item.get("text"), str):
                        return item["text"]

        # 3) choices[0]
        choices = out.get("choices")
        if isinstance(choices, list) and choices:
            ch0 = choices[0]
            if isinstance(ch0, dict):
                if isinstance(ch0.get("text"), str):
                    return ch0["text"]
                msg0 = ch0.get("message")
                if isinstance(msg0, dict) and isinstance(msg0.get("content"), str):
                    return msg0["content"]
                delta0 = ch0.get("delta")
                if isinstance(delta0, dict) and isinstance(delta0.get("content"), str):
                    return delta0["content"]

        # 4) å…¶ä»–å¸¸è§å…œåº•
        for key in ("output_text", "data"):
            v = out.get(key)
            if isinstance(v, str):
                return v

    return ""

# -------- evidence helpers --------

def _extract_meta(hit: Any) -> Dict[str, Any]:
    """ç»Ÿä¸€è·å– metaï¼Œå…¼å®¹ dict / obj ä¸¤ç§å½¢æ€"""
    meta = getattr(hit, "meta", None)
    if meta is None and isinstance(hit, dict):
        meta = hit.get("meta") or {}
    if not isinstance(meta, dict):
        meta = {}
    return meta

def _hit_text(hit: Any) -> str:
    meta = _extract_meta(hit)
    text = meta.get("text") or meta.get("content") or ""
    if not text and isinstance(hit, dict):
        text = hit.get("text") or hit.get("content") or ""
    return str(text or "")

def _hit_doc(hit: Any) -> str:
    meta = _extract_meta(hit)
    return str(meta.get("doc") or meta.get("title") or "")

# -------- é‚»åŸŸæ‰©å±•ï¼ˆæ–°å¢ï¼Œä¿æŒå‘ä¸‹å…¼å®¹ï¼‰ --------

def expand_with_neighbors(
    used: Set[int],
    hits: List[Any],
    window: int = 1,
    max_expand: int = 5,
) -> Set[int]:
    """
    åœ¨å·²æœ‰ hits åŸºç¡€ä¸Šæ‰©å±•é‚»å±…å¥å­ï¼š
      - é€šè¿‡ doc/sent_id è¿ç»­æ€§æ‰©å±•ï¼ˆå‰åå¥ï¼‰
      - æ§åˆ¶æ‰©å±• windowï¼ˆå‡ è·³ï¼‰
      - æœ€å¤šæ‰©å±• max_expand ä¸ªæ–°è¯æ®
    è¿”å›æ›´æ–°åçš„ used ç´¢å¼•é›†åˆ
    """
    if not hits or not used or window <= 0 or max_expand <= 0:
        return used

    # å»ºç´¢å¼•: doc -> [ (sent_id, idx) ... ]ï¼Œæ–¹ä¾¿é‚»å±…æŸ¥æ‰¾
    doc2sents: Dict[str, List[Tuple[int, int]]] = {}
    for idx, h in enumerate(hits):
        meta = _extract_meta(h)
        doc = str(meta.get("doc") or "")
        sid_val = meta.get("sent_id") if meta is not None else None
        try:
            sid = int(sid_val) if sid_val is not None else -1
        except Exception:
            sid = -1
        if sid >= 0:
            doc2sents.setdefault(doc, []).append((sid, idx))

    # æŒ‰å¥ id æ’åº
    for lst in doc2sents.values():
        lst.sort(key=lambda x: x[0])

    expanded: Set[int] = set(used)
    added = 0

    for idx in list(used):
        if added >= max_expand:
            break
        h = hits[idx]
        meta = _extract_meta(h)
        doc = str(meta.get("doc") or "")
        sid_val = meta.get("sent_id")
        try:
            sid = int(sid_val) if sid_val is not None else -1
        except Exception:
            sid = -1
        if sid < 0 or doc not in doc2sents:
            continue

        sent_list = doc2sents[doc]  # å·²æ’åº
        # å»ºç«‹ sid -> idx çš„å¿«æŸ¥
        sid2idx = {s: j for s, j in sent_list}

        for d in range(1, window + 1):
            for sign in (-1, 1):
                neighbor_sid = sid + d * sign
                j = sid2idx.get(neighbor_sid)
                if j is not None and j not in expanded:
                    expanded.add(j)
                    added += 1
                    if added >= max_expand:
                        return expanded

    return expanded

# -------- è¯æ®é€‰æ‹©ï¼ˆä¸¥æ ¼ä¿ç•™æ—§ç­¾åä¸è¾“å‡ºï¼›å†…éƒ¨å¢å¼ºï¼Œä½†ä¸æ”¹å˜è¡Œä¸ºè¾¹ç•Œï¼‰ --------

def select_evidence_for_steps(
    steps: List[str],
    hits: Iterable[Any],
    per_step_k: int = 2,
    min_score: float = 0.0,
    require_entities: List[str] | None = None,
    neighbor_window: int = 1,       # ğŸ”¥ æ–°å¢
    neighbor_max_expand: int = 5,   # ğŸ”¥ æ–°å¢
) -> Tuple[List[List[int]], set]:
    """
    ä¸ºæ¯ä¸ª step é€‰æ‹© top-K è¯æ®ï¼Œæ”¯æŒ:
      - min_score: æœ€ä½ç›¸å…³æ€§é˜ˆå€¼
      - require_entities: ä»…ä¿ç•™å«æœ‰è¿™äº›å®ä½“çš„å¥å­ï¼ˆæ—§é€»è¾‘ï¼šå¼ºè¿‡æ»¤ï¼‰
    ã€å¢å¼ºä½†ä¸ç ´åæ—§æ¥å£ã€‘ï¼š
      - è‹¥å‘½ä¸­ meta ä¸­çš„è§„èŒƒåŒ–åˆ†ï¼šèåˆ( text:0.5, dense:0.3, graph:0.2 )ï¼Œæ— åˆ™å›é€€çº¯ lexical
      - å®ä½“â€œè½¯åŠ æƒâ€å¹¶æœªæ›¿ä»£æ—§çš„ require_entities å¼ºè¿‡æ»¤ï¼›ä¸ºäº†å®Œå…¨å…¼å®¹ï¼Œè¿™é‡Œä»ä¿ç•™å¼ºè¿‡æ»¤åˆ†æ”¯
      - è‡ªåŠ¨é‚»åŸŸæ‰©å±•ï¼ˆwindow=1ï¼Œmax_expand=per_step_kï¼‰ï¼Œä¿è¯å¥é—´è¿ç»­æ€§
      - coverage ä¿åº•ï¼šå¦‚æœæŸæ­¥ä¸è¶³ per_step_kï¼Œå›é€€å…¨å±€é«˜åˆ†è¡¥é½
    """
    H = list(hits)
    step_evidences: List[List[int]] = []
    used = set()

    # é¢„è®¡ç®—å…¨å±€æ’åºï¼ˆç”¨äº coverage ä¿åº•ï¼‰
    global_sorted = sorted(
        range(len(H)),
        key=lambda i: float(getattr(H[i], "score", 0.0)),
        reverse=True
    )

    for s in steps:
        scored: List[Tuple[int, float]] = []
        s_tokens = set(_tokenize(s))  # ä¿ç•™å˜é‡ï¼Œæ–¹ä¾¿æœªæ¥æ‰©å±•

        for i, h in enumerate(H):
            meta = _extract_meta(h)
            text = _hit_text(h)
            if not text:
                continue

            # 1) è¯é¡¹é‡å 
            lex = overlap_score(s, text)

            # 2) è‹¥æœ‰è§„èŒƒåŒ–é€šé“åˆ†ï¼Œèåˆï¼Œå¦åˆ™åªç”¨ lex
            st = float(meta.get("score_text_norm") or 0.0)
            sd = float(meta.get("score_dense_norm") or 0.0)
            sg = float(meta.get("score_graph_norm") or 0.0)

            if (st + sd + sg) > 0.0:
                # èåˆåˆ†ï¼šæŒ‰æƒé‡ç»¼åˆï¼ˆç»éªŒæƒé‡ï¼›ä¸æ”¹å˜æ—§é€»è¾‘æ’åºçš„å…œåº•ï¼‰
                fused_chan = 0.5 * st + 0.3 * sd + 0.2 * sg
                score = 0.6 * lex + 0.4 * fused_chan
            else:
                score = lex

            # 3) æ—§é€»è¾‘ï¼šå¼ºè¿‡æ»¤ require_entities
            if require_entities:
                tl = text.lower()
                if not any(ent.lower() in tl for ent in require_entities):
                    # å¼ºè¿‡æ»¤åˆ†æ”¯ï¼šå’Œæ—§ç‰ˆå®Œå…¨ä¸€è‡´
                    if score < min_score:
                        continue
                    # ç›´æ¥è·³è¿‡è¿™æ¡ï¼ˆä¸åŠ åˆ†ï¼‰
                    # ä½†ä¸ºäº†å°½é‡ä¿ç•™ recallï¼Œæˆ‘ä»¬ç»§ç»­è®¡ç®—ä¸‹ä¸€æ¡
                    continue

            if score >= min_score and score > 0:
                scored.append((i, score))

        scored.sort(key=lambda x: x[1], reverse=True)
        picked = [i for i, _ in scored[:max(1, per_step_k)]]

        # â€”â€” é‚»åŸŸæ‰©å±•ï¼ˆæ–°å¢ï¼Œä¸æ”¹å˜è¿”å›ç±»å‹ï¼‰â€”â€”
        if picked:
            picked_set = expand_with_neighbors(set(picked), H, window=neighbor_window, max_expand=max(neighbor_max_expand, per_step_k))
            # ä»ä¿æŒå»é‡&é™åˆ¶
            picked = list(picked_set)
            # ä¸ºäº†å¯æ§ï¼šå›åˆ°â€œæŒ‰åŸå…ˆå¾—åˆ†æ’åºâ€çš„ç¨³å®šæ€§
            picked.sort(key=lambda i: next((sc for idx, sc in scored if idx == i), 0.0), reverse=True)
            picked = picked[:max(1, per_step_k)]

        # â€”â€” coverage ä¿åº•ï¼ˆæ–°å¢ï¼Œä¸æ”¹å˜è¿”å›ç±»å‹ï¼‰â€”â€”
        if len(picked) < per_step_k:
            for gi in global_sorted:
                if gi not in picked:
                    picked.append(gi)
                if len(picked) >= per_step_k:
                    break

        step_evidences.append(picked)
        used.update(picked)

    return step_evidences, used

# -------- citations --------

def _dedup_keep_order(indices: Iterable[int]) -> List[int]:
    seen = set()
    ordered = []
    for i in indices:
        if i not in seen:
            seen.add(i)
            ordered.append(i)
    return ordered

def build_citation_block(hits: List[Any], indices: Iterable[int]) -> str:
    """
    ç”Ÿæˆç¨³å®šå¯å¤ç°çš„å¼•ç”¨å—ã€‚
    - å»é‡
    - æŒ‰ç´¢å¼•å‡åºæ’åºï¼Œé¿å… set æ— åº
    - è¾“å‡ºæ ¼å¼ä¿æŒä¸å˜
    """
    try:
        idx_list = sorted(set(int(i) for i in indices))
    except Exception:
        idx_list = _dedup_keep_order(indices)

    lines = []
    for j, i in enumerate(idx_list, 1):
        if i < 0 or i >= len(hits):
            logger.debug("Citation index out of range: %s", i)
            continue
        h = hits[i]
        meta = _extract_meta(h)
        doc = str(meta.get("doc") or meta.get("title") or "")
        sid = str(meta.get("sent_id") or meta.get("sid") or "")
        text = str(meta.get("text") or meta.get("content") or "").replace('"', 'â€œ')
        lines.append(f"[#{j}] (doc={doc}, sent_id={sid}) \"{text}\"")
    return "\n".join(lines)

# -------- majority vote --------

def majority_vote(candidates: List[str]) -> Tuple[str, Dict[str, int]]:
    votes = Counter(normalize_answer(c) for c in candidates if c and c.strip())
    if not votes:
        return "", {}
    best_norm, _ = votes.most_common(1)[0]
    for c in candidates:
        if normalize_answer(c) == best_norm:
            return c, dict(votes)
    return candidates[0], dict(votes)